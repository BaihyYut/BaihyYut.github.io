<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tao Lu</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: white;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 1px 8px rgba(0,0,0,0.05);
            overflow: hidden;
        }

        .header {
            padding: 40px;
            background: white;
            color: #333;
            border-bottom: 1px solid #f0f0f0;
        }

        .profile-section {
            display: flex;
            align-items: center;
            gap: 40px;
            margin-bottom: 20px;
        }

        .profile-image {
            width: 200px;
            height: 250px;
            border-radius: 10px;
            object-fit: cover;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .profile-info h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 400;
        }

        .chinese-name {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 20px;
        }

        .contact-info {
            display: flex;
            align-items: center;
            gap: 20px;
            margin-bottom: 20px;
        }

        .email-image {
            height: 32px;
            opacity: 1;
        }

        .links {
            display: flex;
            gap: 20px;
        }

        .links a {
            color: #4a90e2;
            text-decoration: none;
            padding: 8px 16px;
            border: 2px solid #4a90e2;
            border-radius: 25px;
            transition: all 0.3s ease;
            font-size: 0.9em;
        }

        .links a:hover {
            background: #4a90e2;
            color: white;
        }

        .content {
            padding: 40px;
            position: relative;
        }

        .bio {
            font-size: 1.1em;
            line-height: 1.8;
            margin-bottom: 40px;
            color: #555;
            text-align: justify;
            padding-left: 15px;
            border-left: 4px solid #e9ecef;
        }

        .section-title {
            font-size: 2em;
            color: #333;
            margin-bottom: 30px;
            font-weight: 300;
            position: relative;
            padding-bottom: 10px;
            padding-left: 15px;
            border-left: 4px solid #4a90e2;
        }

        .section-title::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 15px;
            width: 50px;
            height: 3px;
            background: linear-gradient(135deg, #4a90e2 0%, #357abd 100%);
            border-radius: 2px;
        }

        .publication {
            margin-bottom: 30px;
            padding: 25px;
            background: linear-gradient(135deg, #ffffff 0%, #fafbfc 100%);
            border-radius: 8px;
            border: 1px solid #f0f0f0;
            border-left: 4px solid #4a90e2;
            box-shadow: 0 2px 12px rgba(74, 144, 226, 0.08);
            transition: transform 0.2s ease, box-shadow 0.2s ease, border-left 0.2s ease;
            position: relative;
            overflow: hidden;
        }

        .publication::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(74, 144, 226, 0.05), transparent);
            transition: left 0.5s ease;
        }

        .publication:hover::before {
            left: 100%;
        }

        .publication:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(74, 144, 226, 0.15);
            border-left: 6px solid #357abd;
        }

        .publication-title {
            font-size: 1.2em;
            color: #333;
            margin-bottom: 8px;
            font-weight: 500;
            line-height: 1.4;
            position: relative;
            transition: color 0.2s ease;
        }

        .publication:hover .publication-title {
            color: #2c3e50;
        }

        .publication-authors {
            color: #666;
            margin-bottom: 8px;
            font-size: 0.95em;
        }

        .publication-venue {
            color: #444;
            margin-bottom: 12px;
            font-weight: 500;
        }

        .publication-venue .highlight {
            color: #4a90e2;
            font-weight: 600;
        }

        .publication-links {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
        }

        .publication-links a {
            color: #4a90e2;
            text-decoration: none;
            font-size: 0.9em;
            padding: 4px 8px;
            border-radius: 4px;
            transition: all 0.2s ease;
        }

        .publication-links a:hover {
            background: #4a90e2;
            color: white;
        }

        .activities {
            margin-top: 40px;
            padding: 25px;
            background: linear-gradient(135deg, #ffffff 0%, #fafbfc 100%);
            border-radius: 8px;
            border: 1px solid #f0f0f0;
            border-left: 4px solid #4a90e2;
            box-shadow: 0 2px 12px rgba(74, 144, 226, 0.08);
            transition: transform 0.2s ease, box-shadow 0.2s ease, border-left 0.2s ease;
        }

        .activities:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(74, 144, 226, 0.12);
            border-left: 6px solid #357abd;
        }

        .activities h2 {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 15px;
            font-weight: 400;
        }

        .activities li {
            margin-bottom: 10px;
            color: #555;
            font-size: 0.95em;
        }

        .footer {
            text-align: center;
            padding: 20px;
            color: #888;
            font-size: 0.85em;
            border-top: 1px solid #f0f0f0;
        }

        .footer a {
            color: #4a90e2;
            text-decoration: none;
        }

        @media (max-width: 768px) {
            .profile-section {
                flex-direction: column;
                text-align: center;
            }
            
            .profile-info h1 {
                font-size: 2em;
            }
            
            .links {
                justify-content: center;
            }
            
            .publication-links {
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="profile-section">
                <img src="assets/lutao2023.png" alt="Tao Lu" class="profile-image">
                <div class="profile-info">
                    <h1>Tao Lu</h1>
                    <div class="chinese-name">鲁涛</div>
                    <div class="contact-info">
                        <img src="assets/email.png" alt="Email" class="email-image">
                    </div>
                    <div class="links">
                        <a href="https://scholar.google.com/citations?user=Ch28NiIAAAAJ&hl=en" target="_blank">Google Scholar</a>
                        <a href="assets/TaoLu_CV.pdf" target="_blank">CV</a>
                    </div>
                </div>
            </div>
        </div>

        <div class="content">
            <div class="bio">
                I'm a postdoc at Brown University, advised by <a href="https://cs.brown.edu/people/ssrinath/" style="color: #4a90e2;">Srinath Sridhar</a>. I received my PhD from Nanjing University in 2023, supervised by <a href="https://mcg.nju.edu.cn/member/gswu/index.html" style="color: #4a90e2;">Prof. Gangshan Wu</a> and <a href="https://wanglimin.github.io/" style="color: #4a90e2;">Prof. Limin Wang</a>. My research focuses on perceiving and understanding the 3D world through both semantic and geometric approaches. Before coming to Brown, I was engaged in research on general and user-friendly novel view rendering methods at the Shanghai AI Lab. My long-term goal is to integrate these insights and methods to develop a more powerful 3D content creation system to facilitate the interaction in a virtual world.
            </div>

            <h2 class="section-title">Publications</h2>
            
            <div class="publication">
                <div class="publication-title">AnySplat: Feed-forward 3D Gaussian Splatting from Unconstrained Views</div>
                <div class="publication-authors">Lihan Jiang*, Yucheng Mao*, Linning Xu, <strong>Tao Lu</strong>, Kerui Ren, Yichen Jin, Xudong Xu, Mulin Yu, Jiangmiao Pang, Feng Zhao, Dahua Lin, and Bo Dai</div>
                <div class="publication-venue">arxiv, 2025</div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/anysplat/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/pdf/2505.23716?" target="_blank">arXiv</a>
                    <a href="https://github.com/OpenRobotLab/AnySplat" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Horizon-GS: Unified 3D Gaussian Splatting for Large-Scale Aerial-to-Ground Scenes</div>
                <div class="publication-authors">Lihan Jiang*, Kerui Ren*, Mulin Yu, Linning Xu, Junting Dong, <strong>Tao Lu</strong>, Feng Zhao, Dahua Lin, and Bo Dai</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2025</div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/horizon-gs/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/pdf/2412.01745" target="_blank">arXiv</a>
                    <a href="https://github.com/OpenRobotLab/HorizonGS" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Proc-GS: Procedural building generation for city assembly with 3D Gaussians</div>
                <div class="publication-authors">Yixuan Li, Xingjian Ran, Linning Xu, <strong>Tao Lu</strong>, Mulin Yu, Zhenzhi Wang, Yuanbo Xiangli, Dahua Lin, and Bo Dai</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2025 (workshop)</div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/procgs/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/abs/2412.07660" target="_blank">arXiv</a>
                    <a href="https://github.com/city-super/ProcGS/" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Art3D: Training-Free 3D Generation from Flat-Colored Illustration</div>
                <div class="publication-authors">Xiaoyan Cong, Jiayi Shen, Zekun Li, Rao Fu, <strong>Tao Lu</strong>, Srinath Sridhar</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2025 (workshop)</div>
                <div class="publication-links">
                    <a href="https://joy-jy11.github.io/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/pdf/2504.10466" target="_blank">arXiv</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians</div>
                <div class="publication-authors">Kerui Ren*, Lihan Jiang*, <strong>Tao Lu</strong>, Mulin Yu, Linning Xu and Bo Dai†</div>
                <div class="publication-venue"><span class="highlight">TPAMI</span>, to appear</div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/octree-gs/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/abs/2403.17898" target="_blank">arXiv</a>
                    <a href="https://github.com/city-super/Octree-GS" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">MixRF: Universal Mixed Radiance Fields with Points and Rays Aggregation</div>
                <div class="publication-authors">Haiyang Bai, <strong>Tao Lu</strong>, Jiaqi Zhu, Wei Huang, Chang Gou, Jie Guo, Lijun Chen, Yanwen Guo</div>
                <div class="publication-venue"><span class="highlight">TVCG</span></div>
                <div class="publication-links">
                    <a href="https://ieeexplore.ieee.org/document/11007514" target="_blank">Paper</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">GSDF: 3DGS Meets SDF for Improved Rendering and Reconstruction</div>
                <div class="publication-authors">Mulin Yu*, <strong>Tao Lu</strong>*, Linning Xu, Lihan Jiang, Yuanbo Xiangli†, and Bo Dai</div>
                <div class="publication-venue"><span class="highlight">NeurIPS</span>, 2024</div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/GSDF/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/abs/2403.16964" target="_blank">arXiv</a>
                    <a href="https://github.com/city-super/GSDF" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering</div>
                <div class="publication-authors"><strong>Tao Lu</strong>*, Mulin Yu*, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin and Bo Dai†</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2024, <strong>highlight</strong></div>
                <div class="publication-links">
                    <a href="https://city-super.github.io/scaffold-gs/" target="_blank">Project page</a>
                    <a href="https://arxiv.org/abs/2312.00109" target="_blank">arXiv</a>
                    <a href="https://github.com/city-super/Scaffold-GS" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">LinK: Linear Kernel for LiDAR-based 3D Perception</div>
                <div class="publication-authors"><strong>Tao Lu</strong>, Xiang Ding, Haisong Liu, Gangshan Wu and Limin Wang†</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2023</div>
                <div class="publication-links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lu_LinK_Linear_Kernel_for_LiDAR-Based_3D_Perception_CVPR_2023_paper.html" target="_blank">Conference</a>
                    <a href="https://arxiv.org/abs/2303.16094" target="_blank">arXiv</a>
                    <a href="https://github.com/MCG-NJU/LinK" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">Learning Optical Flow and Scene Flow with Bidirectional Camera-LiDAR Fusion</div>
                <div class="publication-authors">Haisong Liu, <strong>Tao Lu</strong>, YihuiXu, Jia Liu, and Limin Wang†</div>
                <div class="publication-venue"><span class="highlight">TPAMI</span>, 2023, to appear</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/pdf/2303.12017.pdf" target="_blank">arXiv</a>
                    <a href="https://github.com/MCG-NJU/CamLiFlow" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">APP-Net: Auxiliary-Point-Based Push and Pull Operations for Efficient Point Cloud Recognition</div>
                <div class="publication-authors"><strong>Tao Lu</strong>, Chunxu Liu, Youxin Chen, Gangshan Wu and Limin Wang†</div>
                <div class="publication-venue"><span class="highlight">TIP</span>, 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2205.00847" target="_blank">arXiv</a>
                    <a href="https://github.com/MCG-NJU/APP-Net" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos</div>
                <div class="publication-authors">Haisong Liu, Teng Yao, <strong>Tao Lu</strong>, Haiguang Wang, Limin Wang†</div>
                <div class="publication-venue"><span class="highlight">ICCV</span>, 2023</div>
                <div class="publication-links">
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf" target="_blank">Conference</a>
                    <a href="https://arxiv.org/abs/2308.09244" target="_blank">arXiv</a>
                    <a href="https://github.com/MCG-NJU/SparseBEV" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">CamLiFlow: Bidirectional camera-LiDAR fusion for joint optical flow and scene flow estimation</div>
                <div class="publication-authors">Haisong Liu, <strong>Tao Lu</strong>, Yihui Xu, Jia Liu, Wenjie Li, Lijun Chen</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2022, <strong>(Oral)</strong></div>
                <div class="publication-links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.pdf" target="_blank">Conference</a>
                    <a href="https://arxiv.org/abs/2111.10502" target="_blank">arXiv</a>
                    <a href="https://github.com/MCG-NJU/CamLiFlow" target="_blank">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="publication-title">CGA-Net: Category Guided Aggregation for Point Cloud Semantic Segmentation</div>
                <div class="publication-authors"><strong>Tao Lu</strong>, Limin Wang† and Gangshan Wu</div>
                <div class="publication-venue"><span class="highlight">CVPR</span>, 2021</div>
                <div class="publication-links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_CGA-Net_Category_Guided_Aggregation_for_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.html" target="_blank">Conference</a>
                    <a href="https://github.com/MCG-NJU/CGA-Net" target="_blank">Code</a>
                </div>
            </div>

            <div class="activities">
                <h2>Activities</h2>
                <ul>
                    <li><strong>Reviewer</strong>: CVPR, ICCV, ECCV, NeurIPS, SIGGRAPH Asia, AAAI, TPAMI, IJCV...</li>
                </ul>
            </div>
        </div>

        <div class="footer">
            Designed by Claude 4.
        </div>
    </div>
</body>
</html>